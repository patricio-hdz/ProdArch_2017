---
title: "Proyecto Métodos Analíticos"
author: "Alejandro Daniel Pérez Palacios, Víctor Patricio Hernández Degollado"
date: "28 de mayo de 2018"
output: html_document
---

```{r setup,include=FALSE,message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documentos/Metodos Analiticos/ProyectoFinal/")
```

## Los datos

## Motivación del desarrollo

## Approaches

Se probaron diversos enfoques para lograr una recomendación exitosa y útil para el negocio. Como primer paso se tomaron los datos completos de la base y se resumieron de tal manera que contáramos que contaramos con el ID del usuario (Id), la ruta en la que viajó (Route), el número de viajes (numberTrips) y un identificador del costo promedio (AvgCost): 

```{r echo=FALSE, warning=FALSE,message=FALSE}
library(tidyverse)
library(readr)
library(kableExtra)
library(ggplot2)
library(scales)
datos<-read_csv("Datos2.csv")
fareclass<-data.frame(FareClass=c("Y","M","Q","K","H","V","G","B","W","Z","F","N","J","L"),
                      valor_fc=seq(from=14,to=1,by=-1))
datos2 <- datos %>%
          inner_join(fareclass) %>%
          group_by(Id,Route) %>%
          mutate(numberTrips=n(),AvgCost=mean(valor_fc)) %>%
          distinct(Id,Route,numberTrips,AvgCost)

knitr::kable(datos2%>%head(10),digits = 2,"html")%>%kable_styling("striped", full_width = F)%>%add_footnote(c("Las rutas se resumen con las 3 siglas del aeropuerto"),notation="symbol")
```

Para el caso de recomendación de peliculas contábamos con una calificación explícita de las películas, contrario a lo que tenemos en nuestra base en donde solo contamos con cierta información del viaje. Un primer intento pudiera ser crear una recomendación de acuerdo a retroalimentación implícita al utilizar otras variables con las que contamos. Otro enfoque, por el que optamos en este proyecto, es el de encontrar o crear una variable que nos ayude a resumir la información del viaje así como la calificación del usuario lo hace con las películas. Para esto se probaron las siguientes variables:

$$Score1=numberTrips-AvgCost$$
$$Score2=numberTrips*AvgCost$$

Ambos cálculos son útiles para el negocio de la siguiente manera:

  * Score1: identificar que aunque el cliente viaje mucho un costo alto puede resultar incómodo y resultar en una mala experiencia.
  * Score2: identificar que el costo total promedio de los viajes del usuario por ruta.
  
Se llegó a la conclusión de que el Score2 resulta más interpretable y de mayor ayuda para nuestro objetivo: la recomendación de rutas.

Una vez que encontramos la medida resumen adecuada probamos un enfoque de recomendación de acuerdo al modelo de referencia. Calcular el score no fue de manera directa ya que nos enfrentamos a diversos problemas:

  * Hay usuarios que han viajado más de 20 veces en nuestra ventana de observación.
  * Los datos están en escalas distintas y pueden llevarnos a resultados inesperados.
  * Utilizar toda la base implicaría considerar aquellos clientes que sólo viajaron una vez en la ventana de observación, se consideró que un viajero frecuente (promedio) ayudaría mas al objetivo debido a que registró viajes en más de una ruta (símil a ver más de una pelicula por usuario y que su promedio sea representativo).
  
Para resolver esto se tomaron únicamente los usuarios que viajaron al menos 2 veces en la ventana de observación y a lo más 14.

```{r echo=TRUE, warning=FALSE,message=FALSE}
datos3 <- datos2 %>%
  filter(numberTrips<=14) %>%
  group_by(Id) %>%
  mutate(rutas=n()) %>%
  filter(rutas>1)
```

Además normalizamos los datos para eliminar los efectos de escala:

```{r echo=TRUE, warning=FALSE,message=FALSE}
min_ntrips=min(datos3$numberTrips)
max_ntrips=max(datos3$numberTrips)

min_cost=min(datos3$AvgCost)
max_cost=max(datos3$AvgCost)

datos3 <- datos3 %>%
          mutate(scale_ntrip=(numberTrips)/(max_ntrips-min_ntrips),scale_cost=(AvgCost-min_cost)/(max_cost-min_cost))%>%
          mutate(score=scale_ntrip*scale_cost)
```

Definiremos un primer sistema de recomendación con lo siguiente: 
```{block2, type='resumen'}
Si $x_{ij}$ es el score del cliente $i$ por la ruta $j$, entonces nuestra predicción
es
$$\hat{x}_{ij} = \hat{b}_j +  (\hat{a}_i-\hat{\mu} ) $$

donde $a_i$ indica un nivel general de score del cliente $i$, y $b_j$ es el nivel general de score por la ruta $j$. 
```

Diremos que:

1. Media general
$$\hat{\mu} =\frac{1}{T}\sum_{s,t} x_{st}$$
2. Promedio del score de usuario $i$ 
$$\hat{a}_i =\frac{1}{M_i}\sum_{t} x_{i,t} $$
3. Promedio de score de la ruta $j$ 
$$\hat{b}_j =\frac{1}{N_j}\sum_{s} x_{s,j}$$

Ya definido este enfoque dividimos nuestra base en entrenamiento y validación y para medir el error de la estimación usaremos el error cuadrático medio.

```{r warning=FALSE,message=FALSE}
#Funcion para calcular el error cuadrático medio:
recm <- function(calif, pred){
  sqrt(mean((calif - pred)^2))
}

#Dividimos en entrenamiento y validación:
set.seed(28882)
valida_usuarios <- sample(unique(datos3$Id), 6000)
valida_rutas <- sample(unique(datos3$Route), 80)
dat_2 <- datos3 %>%
  mutate(valida_usu = Id %in% valida_usuarios) %>%
  mutate(valida_route = Route %in% valida_rutas)

# En validación van aquellas evaluaciones de las rutas y
# usuario que seleccionamos
dat_valida <- filter(dat_2, valida_usu & valida_route)
# En entrenamiento va el resto: algunas evaluaciones de usuarios
# seleccionados van en entrenamiento, por ejemplo (para rutas
# no seleccionadas en validación)
dat_entrena <- filter(dat_2, !valida_usu | !valida_route)

medias_usuario_ent <- dat_entrena %>% 
  group_by(Id) %>%
  summarise(media_usu = mean(score), num_calif_usu = length(score))
medias_rutas_ent <- dat_entrena %>% 
  group_by(Route) %>%
  summarise(media_ruta = mean(score), num_calif_ruta = length(score))
media_gral_ent <- mean(dat_entrena$score)
dat_valida_2 <- dat_valida %>%
  left_join(medias_usuario_ent) %>%
  left_join(medias_rutas_ent) %>%
  mutate(media_gral = media_gral_ent) %>%
  mutate(prediccion = media_ruta + (media_usu - media_gral))
dat_valida_2$prediccion[is.na(dat_valida_2$prediccion)] <- media_gral_ent
dat_valida_2 %>% ungroup %>% summarise(error = recm(score, prediccion))
```
Vemos que el error de validación es relativamente chico, por lo que es posible utilizar este modelo para dar recomendaciones por usuario. Las desventajas que vemos de este modelo son las siguientes:

  1. Vemos en el siguiente histograma que el score general de la población se encuentra por debajo de la media general y que nuestra predicción está un poco más cargada a la derecha con respecto a la media general por lo que podríamos recomendar varios falsos positivos.
  
```{r echo=FALSE,warning=FALSE,message=FALSE}
hist(dat_valida_2$score,col=scales::alpha("red",0.5),main="Score")
hist(dat_valida_2$prediccion,add=T,col=scales::alpha("blue",0.5))
abline(v=media_gral_ent,col="red")
a=paste("Score")
b=paste("Predicción")
legend("topright", c(a,b), col=c("red", "blue","gray"),box.lty = 0, cex=0.75,fill=c("red","blue"))
```
  
  2. Dada la poca información de cada usuario, una recomendación para este nivel en particular puede resultar díficil de implementar y resultar en falsos positivos como vimos en el punto anterior.

Después de ver estos problemas nos hicimos la siguiente pregunta ¿Cómo aprovechamos la información general de cada ruta y usuario para poder hacer recomendaciones más globales? La manera que encontramos de resolver este problema es mediante la similitud entre rutas, es decir, ¿Qué pasaría si encontráramos aquellas rutas similares, en cuanto al score, de tal manera que si un cliente viaja en esta ruta podamos recomendarle otras que sean similares? Para esto se decidió utilizar la similitud coseno del score para cada ruta con respecto a las demás.

Ya definido el enfoque, tomamos los datos de entrenamiento y calculamos la media y número de calificaciones (viajes) por ruta:

```{r echo=FALSE,warning=FALSE,message=FALSE}
dat_entrena_c <- dat_entrena %>%
  group_by(Id) %>%
  mutate(calif_c = score - mean(score))

sim_cos <- function(x,y){
  sum(x*y, na.rm = T)/(sqrt(sum(x^2, na.rm = T))*sqrt(sum(y^2, na.rm = T)))
}
dat_entrena_c$id_seq <- as.numeric(factor(dat_entrena_c$Id))
dat_entrena_2 <- dat_entrena_c %>% 
  ungroup() %>% 
  select(Route, id_seq, score)

medias_rutas <- datos3 %>% group_by(Route) %>% summarise(media_ruta = mean(score), num_calif_ruta = length(score))
medias_p_2 <- medias_rutas
```

Ya que tenemos esta información tomaremos una ruta y calculamos la similitud coseno con respecto al resto de las rutas:

```{r echo=FALSE,warning=FALSE,message=FALSE}
rutas_similares <- function(ruta){
  mi_ruta <- filter(dat_entrena_2, Route==ruta) %>% 
    rename(Route_1 = Route, calif_c_1 = score)
  # vamos a calcular todas las similitudes con mi_peli - esto no es buena
  # idea y discutiremos más adelante cómo evitarlo
  datos_comp <- left_join(dat_entrena_2, mi_ruta)
  # calcular similitudes
  out_sum <- datos_comp %>% 
    group_by(Route) %>%
    summarise(dist = sim_cos(score,calif_c_1)) %>% 
    left_join(medias_p_2)
  out_sum %>% arrange(desc(dist))  %>% select(Route, dist, num_calif_ruta)
}
```

Definimos que una ruta será similar si tuvo un mínimo de 50 calificaciones(viajes) y si similitud coseno es alta. Veamos por ejemplo la ruta Cancún-Tijuana:

```{r echo=FALSE,warning=FALSE,message=FALSE}
ruta="CUNTIJ"
rutas_similares(ruta) %>% filter(num_calif_ruta>50) %>% head(10) %>% knitr::kable()%>%kableExtra::kable_styling("striped", full_width = F) 
```

Notemos que la mayoría de las rutas similares contiene como origen/destino Cancún o Tijuana, rutas que claramente podemos notar como similares. Tambén observemos que hay una ruta que no contiene Cancún ó Tijuana por lo que decidimos hacer un filtro sobre estas rutas similares de tal manera que sólo mostremos rutas que contuvieran el origen/destino (Cancún o Tijuana en este caso), fundamentado en que el origen real del viaje fue alguno de estos puntos y las rutas con este punto inicial serán las mejores a recomendar. De esta manera obtenemos el siguiente resultado para la misma ruta:

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(tidytext)
library(stringr)
ruta="CUNTIJ"
rutas_similares(ruta) %>% filter(num_calif_ruta > 50,str_detect(Route,substr(ruta,1,3)) | str_detect(Route,substr(ruta,4,6))) %>% head(10) %>% knitr::kable()%>%kableExtra::kable_styling("striped", full_width = F) 
```

De esta forma 
